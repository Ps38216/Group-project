{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Group 19 Assignment 1\"\n",
    "author: \"Peter Song, Guy Julian, Moritz Wierlacher, Saleh Alzouman\"\n",
    "date: \"2025-10-01\"\n",
    "\n",
    "format: pdf\n",
    "\n",
    "---\n",
    "\\newpage\n",
    "\\tableofcontents\n",
    "\\listoffigures\n",
    "\\listoftables\n",
    "\\newpage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up\n",
    "\n",
    "## Required libraries\n",
    "\n",
    "Loading the required libraries `dplyr` `lubridate`, `ggplot2`, `PerformanceAnalytics`\n",
    "with `library()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "\n",
    "library(dplyr)\n",
    "library(lubridate)\n",
    "library(ggplot2)\n",
    "library(PerformanceAnalytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "In Part 1 of the analysis, we are asked to undertake an exploratory data analysis task to determine key indicators and metrics for a given stock.\n",
    "\n",
    "To start, we have to load and define our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "full_data <- read.csv(\"compustat_food_bev.csv\")\n",
    "sbux <- filter(full_data, tic == \"SBUX\")\n",
    "wen <- filter(full_data, tic == \"WEN\")\n",
    "pbpb <- filter(full_data, tic == \"PBPB\")\n",
    "cmg <- filter(full_data, tic == \"CMG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we have loaded the full dataset supplied to us in the assignment.\n",
    "\n",
    "Then we used the filter() function to isolate rows and store stocks in their individual datasets. \n",
    "\n",
    "Following the learned best practices, we have named our stock datasets with their corresponding ticker names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Returns\n",
    "\n",
    "Question applicable to Starbucks, Wendy's, Potbelly, and Chipotle.\n",
    "\n",
    "We are asked to add a column with daily return.\n",
    "\n",
    "The formula for daily returns is below. \n",
    "\n",
    "$$\n",
    "return_{daily} = \\frac{(close_{t} - close_{t-1})}{close_{t-1}} \n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "sbux <- mutate(sbux, daily_return_sbux = (prccd / lag(prccd)) - 1)\n",
    "\n",
    "#Wendy's\n",
    "wen <- mutate(wen, daily_return_wen = (prccd / lag(prccd)) - 1)\n",
    "\n",
    "#Potbelly\n",
    "pbpb <- mutate(pbpb, daily_return_pbpb = (prccd / lag(prccd)) - 1)\n",
    "\n",
    "#Chipotle\n",
    "cmg <- mutate(cmg, daily_return_cmg = (prccd / lag(prccd)) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate() function with the name \"daily_return_xxx\". And used the lag() function to lag the closing price by 1 day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-day momentum indicator\n",
    "\n",
    "Question applicable to Starbucks and Chipotle.\n",
    "\n",
    "We are asked to add a column with the 10-day momentum indicator.\n",
    "\n",
    "The formula for the indicator is below. \n",
    "\n",
    "$$\n",
    "momentum_{10-day} = (close_{t} - close_{t-10})\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "sbux <- mutate(sbux, momentum_sbux = (prccd / lag(prccd, n=10L)) - 1) \n",
    "\n",
    "#Chipotle\n",
    "cmg <- mutate(cmg, momentum_cmg = (prccd / lag(prccd, n=10L)) - 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate() function with the name \"momentum_xxx\". And used the lag() function to lag the closing price by 10 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Range\n",
    "\n",
    "Question applicable to Starbucks.\n",
    "\n",
    "We are asked to add a column with the daily range.\n",
    "\n",
    "The formula for the daily range is below. \n",
    "\n",
    "$$\n",
    "range_{daily} = (high_{t} - low_{t})\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "sbux <- mutate(sbux, daily_range_sbux = prchd - prcld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate() function with the name \"daily_range_sbux\" follwing the daily range formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Change\n",
    "\n",
    "Question applicable to Wendy's and Chipotle.\n",
    "\n",
    "We are asked to add a column with volume change.\n",
    "\n",
    "The formula for the volume range is below. \n",
    "\n",
    "$$\n",
    "change_{volume} = volume_{t} - volume_{t-1}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Wendy's\n",
    "wen <- mutate(wen, volume_change_wen = (cshtrd / lag(cshtrd)) - 1)\n",
    "\n",
    "#Chipotle\n",
    "cmg <- mutate(cmg, volume_change_wen = (cshtrd / lag(cshtrd)) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate() function with the name \"volume_change_xxx\" follwing the volume range formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Money Flow Volume Indicator (MFV)\n",
    "\n",
    "Question applicable to Starbucks, Wendy's, Potbelly, and Chipotle.\n",
    "\n",
    "We are asked to add a column with the MFV.\n",
    "\n",
    "The formula for the MFV is below. \n",
    "\n",
    "$$\n",
    "MFV = \\frac{(close_{t} - low_{t})-(high{t} - close_{t})}{high_{t} - low_{t}} * volume_{t}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "sbux <- mutate(sbux, MFV_sbux = (((prccd - prcld) - (prchd - prccd))\n",
    " / (prchd - prcld)) * cshtrd)\n",
    "\n",
    "#Wendy's\n",
    "wen <- mutate(wen, MFV_wen = (((prccd - prcld) - (prchd - prccd))\n",
    " / (prchd - prcld)) * cshtrd)\n",
    "\n",
    "#Potbelly\n",
    "pbpb <- mutate(pbpb, MFV_pbpb = (((prccd - prcld) - (prchd - prccd))\n",
    " / (prchd - prcld)) * cshtrd)\n",
    "\n",
    "#Chipotle\n",
    "cmg <- mutate(cmg, MFV_cmg = (((prccd - prcld) - (prchd - prccd))\n",
    " / (prchd - prcld)) * cshtrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate function with the name \"MFV_xxx\" following the MFV formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overnight return\n",
    "\n",
    "Question applicable to Wendy's and Potbelly.\n",
    "\n",
    "We are asked to add a column with the overnight return.\n",
    "\n",
    "The formula for the overnight return is below. \n",
    "\n",
    "$$\n",
    "return_{overnight} = \\frac{(open_{t} - close_{t-1})}{close_{t-1}}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Wendy's\n",
    "wen <- mutate(wen, overnight_return_wen = (prcod - lag(prccd)) / lag(prccd))\n",
    "\n",
    "#Potbelly\n",
    "pbpb <- mutate(pbpb, overnight_return_pbpb = (prcod - lag(prccd)) / lag(prccd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate function with the name \"overnight_return_xxx\" following the overnight return formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close-Open change\n",
    "\n",
    "Question applicable to Potbelly.\n",
    "\n",
    "We are asked to add a column with the close-open change.\n",
    "\n",
    "The formula for the overnight return is below. \n",
    "\n",
    "$$\n",
    "change_{close-open} = {(close_{t} - close_{t})}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Potbelly\n",
    "pbpb <- mutate(pbpb, close_open_change = prccd - prcod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a column using the mutate function with the name \"close_open_change_pbpb\" following the close-open change formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month & Year\n",
    "\n",
    "Q5 and Q6 ask us to add a column that indicates the month and year, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "sbux <- mutate(sbux, datadate = as.Date(datadate, format = \"%d/%m/%Y\"))\n",
    "sbux <- mutate(sbux, month = month(datadate))\n",
    "sbux <- mutate(sbux, year = year(datadate))\n",
    "\n",
    "#Wendy's\n",
    "wen <- mutate(wen, datadate = as.Date(datadate, format = \"%d/%m/%Y\"))\n",
    "wen <- mutate(wen, month = month(datadate))\n",
    "wen <- mutate(wen, year = year(datadate))\n",
    "\n",
    "#Potbelly\n",
    "pbpb <- mutate(pbpb, datadate = as.Date(datadate, format = \"%d/%m/%Y\"))\n",
    "pbpb <- mutate(pbpb, month = month(datadate))\n",
    "pbpb <- mutate(pbpb, year = year(datadate))\n",
    "\n",
    "#Chipotle\n",
    "cmg <- mutate(cmg, datadate = as.Date(datadate, format = \"%d/%m/%Y\"))\n",
    "cmg <- mutate(cmg, month = month(datadate))\n",
    "cmg <- mutate(cmg, year = year(datadate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lubridate package in R, we were able to extract the information from a Date using month() and year() function.\n",
    "\n",
    "Firstly, we overwrite the original day information and formatting it with the as.Date() function.\n",
    "\n",
    "Then, we were able to create new columns that show the month and year using the mutate() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total trading volume, in June 2023\n",
    "\n",
    "Q7 asks us to calculate the total trading colume in June 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "june_2023_sbux <- filter(sbux, year == 2023 & month == 6)\n",
    "total_june2023_sbux <- sum(june_2023_sbux$cshtrd)\n",
    "\n",
    "#Wendy's\n",
    "june_2023_wen <- filter(wen, year == 2023 & month == 6)\n",
    "total_june2023_wen <- sum(june_2023_wen$cshtrd)\n",
    "#Potbelly\n",
    "june_2023_pbpb <- filter(pbpb, year == 2023 & month == 6)\n",
    "total_june2023_pbpb <- sum(june_2023_pbpb$cshtrd)\n",
    "\n",
    "#Chipotle\n",
    "june_2023_cmg <- filter(cmg, year == 2023 & month == 6)\n",
    "total_june2023_cmg <- sum(june_2023_cmg$cshtrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we used the filter() function to take rows that meet the June 2023 condition.\n",
    "\n",
    "Then we used the sum() function to add together trading volume for June 2023.\n",
    "\n",
    "The total trading volume is stored in each stock's corresponding dataset named total_june2023_xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean daily return\n",
    "\n",
    "Q8 asks us to calculate the mean daily return, over the entire period.\n",
    "\n",
    "The formula for mean daily is below. \n",
    "\n",
    "$$\n",
    "MeanDailyReturn = \\frac{TotalDailyReturn}{Days} \n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "daily_return_sbux <- na.omit(sbux$daily_return_sbux)\n",
    "mean_daily_return_sbux <- sum(daily_return_sbux)/length(daily_return_sbux)\n",
    "\n",
    "#Wendy's\n",
    "daily_return_wen <- na.omit(wen$daily_return_wen)\n",
    "mean_daily_return_wen <- sum(daily_return_wen)/length(daily_return_wen)\n",
    "\n",
    "#Potbelly\n",
    "daily_return_pbpb <- na.omit(pbpb$daily_return_pbpb)\n",
    "mean_daily_return_pbpb <- sum(daily_return_pbpb)/length(daily_return_pbpb)\n",
    "\n",
    "#Chipotle\n",
    "daily_return_cmg <- na.omit(cmg$daily_return_cmg)\n",
    "mean_daily_return_cmg <- sum(daily_return_cmg)/length(daily_return_cmg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we modify our existing daily_return_xxx dataset by omitting the 1st row which shows NA.\n",
    "\n",
    "Then using the formula, we used the sum() function to add together the daily return, and divided it (using the length() function) by the number of days.\n",
    "\n",
    "The mean daily return is stored in each stock's corresponding dataset named mean_daily_return_xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date with the largest positive high price\n",
    "\n",
    "Q9 asks us to find and display the date that saw the largest positive high price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "max_price_sbux <- sbux$datadate[sbux$prchd == max(sbux$prchd)]\n",
    "\n",
    "#Wendy's\n",
    "max_price_wen <- wen$datadate[wen$prchd == max(wen$prchd)]\n",
    "\n",
    "#Potbelly\n",
    "max_price_pbpb <- pbpb$datadate[pbpb$prchd == max(pbpb$prchd)]\n",
    "\n",
    "#Chipotle\n",
    "max_price_cmg <- cmg$datadate[cmg$prchd == max(cmg$prchd)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the max() function to find the maximium value in the daily high price column, and stored it in the stock's corresponding dataset named max_price_xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date with the largest positive daily return\n",
    "\n",
    "Q10 asks us to find and display the date that saw the largest positive daily return.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Starbucks\n",
    "max_daily_return_sbux <- sbux$datadate[daily_return_sbux== max(daily_return_sbux)]\n",
    "\n",
    "#Wendy's\n",
    "max_daily_return_wen <- wen$datadate[daily_return_wen == max(daily_return_wen)]\n",
    "\n",
    "#Potbelly\n",
    "max_daily_return_pbpb <- pbpb$datadate[daily_return_pbpb == max(daily_return_pbpb)]\n",
    "\n",
    "#Chipotle\n",
    "max_daily_return_cmg <- cmg$datadate[daily_return_cmg == max(daily_return_cmg)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used [] to subset rows in the datadate column. Inside the [], we used the max() function to find the maximium value in the NA-omitted daily_return_xxx , and stored it in each stock's corresponding dataset named max_daily_return_xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'GVKEY'</li><li>'iid'</li><li>'datadate'</li><li>'tic'</li><li>'conm'</li><li>'cshtrd'</li><li>'prccd'</li><li>'prchd'</li><li>'prcld'</li><li>'prcod'</li><li>'exchg'</li><li>'sic'</li><li>'daily_return_sbux'</li><li>'momentum_sbux'</li><li>'daily_range_sbux'</li><li>'MFV_sbux'</li><li>'month'</li><li>'year'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'GVKEY'\n",
       "\\item 'iid'\n",
       "\\item 'datadate'\n",
       "\\item 'tic'\n",
       "\\item 'conm'\n",
       "\\item 'cshtrd'\n",
       "\\item 'prccd'\n",
       "\\item 'prchd'\n",
       "\\item 'prcld'\n",
       "\\item 'prcod'\n",
       "\\item 'exchg'\n",
       "\\item 'sic'\n",
       "\\item 'daily\\_return\\_sbux'\n",
       "\\item 'momentum\\_sbux'\n",
       "\\item 'daily\\_range\\_sbux'\n",
       "\\item 'MFV\\_sbux'\n",
       "\\item 'month'\n",
       "\\item 'year'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'GVKEY'\n",
       "2. 'iid'\n",
       "3. 'datadate'\n",
       "4. 'tic'\n",
       "5. 'conm'\n",
       "6. 'cshtrd'\n",
       "7. 'prccd'\n",
       "8. 'prchd'\n",
       "9. 'prcld'\n",
       "10. 'prcod'\n",
       "11. 'exchg'\n",
       "12. 'sic'\n",
       "13. 'daily_return_sbux'\n",
       "14. 'momentum_sbux'\n",
       "15. 'daily_range_sbux'\n",
       "16. 'MFV_sbux'\n",
       "17. 'month'\n",
       "18. 'year'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"GVKEY\"             \"iid\"               \"datadate\"         \n",
       " [4] \"tic\"               \"conm\"              \"cshtrd\"           \n",
       " [7] \"prccd\"             \"prchd\"             \"prcld\"            \n",
       "[10] \"prcod\"             \"exchg\"             \"sic\"              \n",
       "[13] \"daily_return_sbux\" \"momentum_sbux\"     \"daily_range_sbux\" \n",
       "[16] \"MFV_sbux\"          \"month\"             \"year\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Starbucks' Total Trading Volume June 2023 = 151045270\"\n",
      "[1] \"Starbucks' Mean Daily Return = 0.000291046723931375\"\n",
      "[1] \"Starbucks' Largest Positive High Price Date = 2021-07-23\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Starbucks' Largest Positive Daily Return Date = 2022-05-03\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'GVKEY'</li><li>'iid'</li><li>'datadate'</li><li>'tic'</li><li>'conm'</li><li>'cshtrd'</li><li>'prccd'</li><li>'prchd'</li><li>'prcld'</li><li>'prcod'</li><li>'exchg'</li><li>'sic'</li><li>'daily_return_wen'</li><li>'volume_change_wen'</li><li>'MFV_wen'</li><li>'overnight_return_wen'</li><li>'month'</li><li>'year'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'GVKEY'\n",
       "\\item 'iid'\n",
       "\\item 'datadate'\n",
       "\\item 'tic'\n",
       "\\item 'conm'\n",
       "\\item 'cshtrd'\n",
       "\\item 'prccd'\n",
       "\\item 'prchd'\n",
       "\\item 'prcld'\n",
       "\\item 'prcod'\n",
       "\\item 'exchg'\n",
       "\\item 'sic'\n",
       "\\item 'daily\\_return\\_wen'\n",
       "\\item 'volume\\_change\\_wen'\n",
       "\\item 'MFV\\_wen'\n",
       "\\item 'overnight\\_return\\_wen'\n",
       "\\item 'month'\n",
       "\\item 'year'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'GVKEY'\n",
       "2. 'iid'\n",
       "3. 'datadate'\n",
       "4. 'tic'\n",
       "5. 'conm'\n",
       "6. 'cshtrd'\n",
       "7. 'prccd'\n",
       "8. 'prchd'\n",
       "9. 'prcld'\n",
       "10. 'prcod'\n",
       "11. 'exchg'\n",
       "12. 'sic'\n",
       "13. 'daily_return_wen'\n",
       "14. 'volume_change_wen'\n",
       "15. 'MFV_wen'\n",
       "16. 'overnight_return_wen'\n",
       "17. 'month'\n",
       "18. 'year'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"GVKEY\"                \"iid\"                  \"datadate\"            \n",
       " [4] \"tic\"                  \"conm\"                 \"cshtrd\"              \n",
       " [7] \"prccd\"                \"prchd\"                \"prcld\"               \n",
       "[10] \"prcod\"                \"exchg\"                \"sic\"                 \n",
       "[13] \"daily_return_wen\"     \"volume_change_wen\"    \"MFV_wen\"             \n",
       "[16] \"overnight_return_wen\" \"month\"                \"year\"                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Wendy's Total Trading Volume June 2023 = 54557454\"\n",
      "[1] \"Wendy's' Mean Daily Return = 0.000116474712706265\"\n",
      "[1] \"Wendy's Largest Positive High Price Date = 2021-06-08\"\n",
      "[1] \"Wendy's Largest Positive Daily Return Date = 2021-06-07\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'GVKEY'</li><li>'iid'</li><li>'datadate'</li><li>'tic'</li><li>'conm'</li><li>'cshtrd'</li><li>'prccd'</li><li>'prchd'</li><li>'prcld'</li><li>'prcod'</li><li>'exchg'</li><li>'sic'</li><li>'daily_return_pbpb'</li><li>'MFV_pbpb'</li><li>'overnight_return_pbpb'</li><li>'close_open_change'</li><li>'month'</li><li>'year'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'GVKEY'\n",
       "\\item 'iid'\n",
       "\\item 'datadate'\n",
       "\\item 'tic'\n",
       "\\item 'conm'\n",
       "\\item 'cshtrd'\n",
       "\\item 'prccd'\n",
       "\\item 'prchd'\n",
       "\\item 'prcld'\n",
       "\\item 'prcod'\n",
       "\\item 'exchg'\n",
       "\\item 'sic'\n",
       "\\item 'daily\\_return\\_pbpb'\n",
       "\\item 'MFV\\_pbpb'\n",
       "\\item 'overnight\\_return\\_pbpb'\n",
       "\\item 'close\\_open\\_change'\n",
       "\\item 'month'\n",
       "\\item 'year'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'GVKEY'\n",
       "2. 'iid'\n",
       "3. 'datadate'\n",
       "4. 'tic'\n",
       "5. 'conm'\n",
       "6. 'cshtrd'\n",
       "7. 'prccd'\n",
       "8. 'prchd'\n",
       "9. 'prcld'\n",
       "10. 'prcod'\n",
       "11. 'exchg'\n",
       "12. 'sic'\n",
       "13. 'daily_return_pbpb'\n",
       "14. 'MFV_pbpb'\n",
       "15. 'overnight_return_pbpb'\n",
       "16. 'close_open_change'\n",
       "17. 'month'\n",
       "18. 'year'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"GVKEY\"                 \"iid\"                   \"datadate\"             \n",
       " [4] \"tic\"                   \"conm\"                  \"cshtrd\"               \n",
       " [7] \"prccd\"                 \"prchd\"                 \"prcld\"                \n",
       "[10] \"prcod\"                 \"exchg\"                 \"sic\"                  \n",
       "[13] \"daily_return_pbpb\"     \"MFV_pbpb\"              \"overnight_return_pbpb\"\n",
       "[16] \"close_open_change\"     \"month\"                 \"year\"                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Potbelly's Total Trading Volume June 2023 = 6780601\"\n",
      "[1] \"Potbelly's Mean Daily Return = 0.00127986776777775\"\n",
      "[1] \"Potbelly's Largest Positive High Price Date = 2023-04-26\"\n",
      "[1] \"Potbelly's Largest Positive Daily Return Date = 2021-03-12\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'GVKEY'</li><li>'iid'</li><li>'datadate'</li><li>'tic'</li><li>'conm'</li><li>'cshtrd'</li><li>'prccd'</li><li>'prchd'</li><li>'prcld'</li><li>'prcod'</li><li>'exchg'</li><li>'sic'</li><li>'daily_return_cmg'</li><li>'momentum_cmg'</li><li>'volume_change_wen'</li><li>'MFV_cmg'</li><li>'month'</li><li>'year'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'GVKEY'\n",
       "\\item 'iid'\n",
       "\\item 'datadate'\n",
       "\\item 'tic'\n",
       "\\item 'conm'\n",
       "\\item 'cshtrd'\n",
       "\\item 'prccd'\n",
       "\\item 'prchd'\n",
       "\\item 'prcld'\n",
       "\\item 'prcod'\n",
       "\\item 'exchg'\n",
       "\\item 'sic'\n",
       "\\item 'daily\\_return\\_cmg'\n",
       "\\item 'momentum\\_cmg'\n",
       "\\item 'volume\\_change\\_wen'\n",
       "\\item 'MFV\\_cmg'\n",
       "\\item 'month'\n",
       "\\item 'year'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'GVKEY'\n",
       "2. 'iid'\n",
       "3. 'datadate'\n",
       "4. 'tic'\n",
       "5. 'conm'\n",
       "6. 'cshtrd'\n",
       "7. 'prccd'\n",
       "8. 'prchd'\n",
       "9. 'prcld'\n",
       "10. 'prcod'\n",
       "11. 'exchg'\n",
       "12. 'sic'\n",
       "13. 'daily_return_cmg'\n",
       "14. 'momentum_cmg'\n",
       "15. 'volume_change_wen'\n",
       "16. 'MFV_cmg'\n",
       "17. 'month'\n",
       "18. 'year'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"GVKEY\"             \"iid\"               \"datadate\"         \n",
       " [4] \"tic\"               \"conm\"              \"cshtrd\"           \n",
       " [7] \"prccd\"             \"prchd\"             \"prcld\"            \n",
       "[10] \"prcod\"             \"exchg\"             \"sic\"              \n",
       "[13] \"daily_return_cmg\"  \"momentum_cmg\"      \"volume_change_wen\"\n",
       "[16] \"MFV_cmg\"           \"month\"             \"year\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Chipotle's Total Trading Volume June 2023 = 5392605\"\n",
      "[1] \"Chipotle's Mean Daily Return = 0.000674687634951916\"\n",
      "[1] \"Chipotle's Largest Positive High Price Date = 2023-07-19\"\n",
      "[1] \"Chipotle's Largest Positive Daily Return Date = 2022-07-26\"\n"
     ]
    }
   ],
   "source": [
    "#Starbucks\n",
    "colnames(sbux)\n",
    "print(paste(\"Starbucks' Total Trading Volume June 2023 =\",total_june2023_sbux))\n",
    "print(paste(\"Starbucks' Mean Daily Return =\",mean_daily_return_sbux))\n",
    "print(paste(\"Starbucks' Largest Positive High Price Date =\",max_price_sbux))\n",
    "print(paste(\"Starbucks' Largest Positive Daily Return Date =\",max_daily_return_sbux))\n",
    "\n",
    "#Wendy's\n",
    "colnames(wen)\n",
    "print(paste(\"Wendy's Total Trading Volume June 2023 =\",total_june2023_wen))\n",
    "print(paste(\"Wendy's' Mean Daily Return =\",mean_daily_return_wen))\n",
    "print(paste(\"Wendy's Largest Positive High Price Date =\",max_price_wen))\n",
    "print(paste(\"Wendy's Largest Positive Daily Return Date =\",max_daily_return_wen))\n",
    "\n",
    "#Potbelly\n",
    "colnames(pbpb)\n",
    "print(paste(\"Potbelly's Total Trading Volume June 2023 =\",total_june2023_pbpb))\n",
    "print(paste(\"Potbelly's Mean Daily Return =\",mean_daily_return_pbpb))\n",
    "print(paste(\"Potbelly's Largest Positive High Price Date =\",max_price_pbpb))\n",
    "print(paste(\"Potbelly's Largest Positive Daily Return Date =\",max_daily_return_pbpb))\n",
    "\n",
    "#Chipotle\n",
    "colnames(cmg)\n",
    "print(paste(\"Chipotle's Total Trading Volume June 2023 =\",total_june2023_cmg))\n",
    "print(paste(\"Chipotle's Mean Daily Return =\",mean_daily_return_cmg))\n",
    "print(paste(\"Chipotle's Largest Positive High Price Date =\",max_price_cmg))\n",
    "print(paste(\"Chipotle's Largest Positive Daily Return Date =\",max_daily_return_cmg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that we have successfully added the columns asked in Q1-Q6, we have used the head() function to display all the column names.\n",
    "\n",
    "To show our calculated metrics asked in Q7-Q10, we have used the print() function to display our result stored in their corresponding datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Before we can move to regression, we should ensure that the response and\n",
    "explanatory variable are *correlated* - that is, that they share a\n",
    "linear relationship. If they do not share such a relationship, simple\n",
    "linear regression may not be the appropriate analysis.\n",
    "\n",
    "The `chart.Correlation()` function inside the `PerformanceAnalytics`\n",
    "package can help us determine whether columns in a data frame are\n",
    "*correlated*.\n",
    "\n",
    "Let's say we thought that *Apple* returns might have some affect on\n",
    "*Google* returns.\n",
    "\n",
    "#### Google vs. Apple\n",
    "\n",
    "In the next code cell, we'll call the `chart.Correlation()` function\n",
    "and pass in the `GOOG.Returns` and `AAPL.Returns` columns of the data\n",
    "frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'trading_data' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'trading_data' not found\nTraceback:\n",
      "1. chart.Correlation(trading_data[c(\"GOOG.Returns\", \"AAPL.Returns\")])",
      "2. checkData(R, method = \"matrix\")",
      "3. as.matrix(x, ncol = NCOL(x))"
     ]
    }
   ],
   "source": [
    "#| fig-cap: \"Correlation: Google vs Apple Returns\"\n",
    "\n",
    "chart.Correlation(trading_data[c(\"GOOG.Returns\", \"AAPL.Returns\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting output is a **correlation matrix**.\n",
    "\n",
    "-   Top right is the correlation coefficient (*Pearson's r* in this\n",
    "    case), which gives us the strength and direction of the linear\n",
    "    relationship. The asterisks indicate the *significance* of the\n",
    "    coefficient.\n",
    "\n",
    "-   Bottom-left is a scatter-plot of the two variables, visually\n",
    "    illustrating their relationship and helping to identify linearity.\n",
    "\n",
    "-   Top-left and bottom-right we'll see histograms showing the\n",
    "    distribution of prices for each stock and aim to give a *bigger\n",
    "    picture* of the data.\n",
    "\n",
    "**One way** of interpreting coefficients:\n",
    "\n",
    "-   less than 0.2 means weakly or not correlated\n",
    "-   between 0.2 and 0.4 means moderately correlated\n",
    "-   above 0.4 means strongly correlated\n",
    "\n",
    "What are your thoughts on the Google vs Apple relationship? If there is\n",
    "a linear correlation, we can move on to regression.\n",
    "\n",
    "### Fitting a model\n",
    "\n",
    "To start simple linear regression, we use the `lm()` function. There are\n",
    "two important arguments:\n",
    "\n",
    "-   `formula` where a tilde (\\~) separates response (left) and\n",
    "    explanatory (right)\n",
    "-   `data` which is the data frame in which response and explanatory are\n",
    "    column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Simple linear regression model\n",
    "\n",
    "lm_google_apple  <- lm(formula = GOOG.Returns ~ AAPL.Returns, data = trading_data)\n",
    "summary(lm_google_apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief explanation of the model summary above:\n",
    "\n",
    "-   **Residuals** These represent the differences between the observed\n",
    "    and predicted daily returns of Google.\n",
    "\n",
    "-   Our **Coefficients**:\n",
    "\n",
    "    -   **Intercept** is the predicted daily return for Google when\n",
    "        Apple's return is 0%.\n",
    "    -   **AAPL.Returns** indicates that For every 1 percentage point\n",
    "        increase in Apple's daily return, Google's daily return is\n",
    "        predicted to increase by approximately 0.7493 percentage points.\n",
    "\n",
    "-   The **t-value** & **p-value** validate the significance of the\n",
    "    coefficient. A high t-value / low p-value mean that the coefficient\n",
    "    is likely significant.\n",
    "\n",
    "-   **R-squared** tells us that 52.63% of the variability in Google's\n",
    "    daily returns can be explained by Apple's daily returns. The\n",
    "    Adjusted R-square is *adjusted* for the number of predictors, which\n",
    "    is useful for models with multiple predictors.\n",
    "\n",
    "The model can be interpreted in the format of $y = a + bx$\n",
    "\n",
    "$$ GOOG.Return = -0.001096 + 0.7493 * AAPL.Return $$\n",
    "\n",
    "If we are pleased with our model, we can draw a regression line on a\n",
    "plot of our data.\n",
    "\n",
    "##### Exercise 4B: Plotting\n",
    "\n",
    "Plot Google daily returns vs. Apple daily returns, with the explanatory\n",
    "variable on the y-axis. Don't forget to filter out NA values - here\n",
    "we'll use `na.omit()`\n",
    "\n",
    "We'll get the model predictions with `predict()`, then save the model\n",
    "predictions into our dataframe, and then use the `geom_line()` function\n",
    "to add our regression line to our plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#| fig-cap: \"Regression: Apple VS Google\"\n",
    "\n",
    "# Drop NAs\n",
    "trading_data <- na.omit(trading_data)\n",
    "\n",
    "# Add the model predictions to our data\n",
    "trading_data$model <- predict(lm_google_apple)\n",
    "\n",
    "# Plot a scatter plot\n",
    "ggplot(trading_data, aes(AAPL.Returns, GOOG.Returns)) +\n",
    "  geom_point() +\n",
    "  geom_line(aes(y = model, colour = \"Regression Line\")) +\n",
    "  labs(title = \"Google vs Apple Returns & Linear Regression\",\n",
    "       colour = \"Legend\", x = \"Apple Returns\", y = \"Google Returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "As the name implies, multiple linear regression determines if *more than\n",
    "one* explanatory variable is involved with predicting a dependent\n",
    "variable.\n",
    "\n",
    "Today we'll work with an established model in portfolio management\n",
    "called the *Fama French 3-Factor* model, after its two creators (Fama &\n",
    "French) and three accepted market risk factors. We've provided Fama\n",
    "French 3-factor (FF3) data for *ff3_wk4.csv* file. Let's load that data\n",
    "now and have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# load data with FF3\n",
    "\n",
    "ff3_data <- read.csv(\"ff3_wk4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE** FF3 factors are in percentages, but we'll need them\n",
    "in their decimal for our further analyses. We can convert multiple\n",
    "columns like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# This piece of code takes all the columns except the first (Date)\n",
    "# and divides them by 100\n",
    "\n",
    "ff3_data[-1] <- ff3_data[-1] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same `lm()` function to implement multiple linear regression.\n",
    "Recall that `lm()` expects data to be in one single data frame. To\n",
    "achieve this, we'll use the `merge()` function to join the `ff3` data\n",
    "with our `trading` data.\n",
    "\n",
    "### Merging Dataframes\n",
    "\n",
    "For a basic merge, we provide the names of two data frames as arguments\n",
    "to `merge()`. We also provide the `by` argument, to indicate *the column\n",
    "we want to merge on*.\n",
    "\n",
    "The *column to merge on* must have the same column name, type and format\n",
    "in both dataframes. Fortunately for us, this is already the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Merging dataframes\n",
    "\n",
    "merged_data <- merge(trading_data, ff3_data, by = \"Date\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excess Returns\n",
    "\n",
    "Let's continue using Google's data for practice. Multiple regression\n",
    "with FF3 requires **excess returns** as the response variable. To get\n",
    "excess returns, we first calculate simple daily returns. From the daily\n",
    "returns, we subtract the current risk free rate - an approximate\n",
    "indicator of an investment free of risk, often a short-term government\n",
    "bond - to get what we call excess returns.\n",
    "\n",
    "Using the code cell below, create a new column in the data frame called\n",
    "`GOOG.ExcessReturns`, correctly populating it with excess returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Excess returns\n",
    "\n",
    "merged_data$GOOG.ExcessReturns <- merged_data$GOOG.Returns - merged_data$RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting our model\n",
    "\n",
    "The pseudo-code formula for fitting our FF3 model is: \n",
    "$$\n",
    "y = Mkt.RF + SMB + HML\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Multiple regression model\n",
    "\n",
    "lm_ff3_google <- lm(formula = GOOG.ExcessReturns ~ Mkt.RF + SMB + HML, \n",
    "                    data = merged_data)\n",
    "summary(lm_ff3_google)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the three variables we're using to explain Google's\n",
    "performance:\n",
    "\n",
    "-   **Mkt.RF (Market Risk Premium)** If this coefficient is positive, it\n",
    "    suggests that the stock tends to move in the same direction as the\n",
    "    wider market (and vice versa). A positive coefficient greater than 1\n",
    "    indicates higher volatility than the market, while a positive\n",
    "    coefficient less than 1 indicates lower volatility than the market.\n",
    "\n",
    "-   **SMB (Small Minus Big)** A positive, significant coefficient here\n",
    "    suggests that the stock's excess returns behave more like those of\n",
    "    small-cap stocks, (even if Google itself is a large-cap company.)\n",
    "\n",
    "-   **HML (High Minus Low)** A positive coefficient suggests the stock\n",
    "    behaves more like a \"value\" stock (think stability - Coca-Cola,\n",
    "    Berkshire Hathaway). A negative coefficient implies it behaves more\n",
    "    like a \"growth\" stock (think growth - Amazon, Tesla)\n",
    "\n",
    "The model can be interpreted in the format of\n",
    "$y = a + b_1x_1 + b_2x_2+b_3x_3$ \n",
    "\n",
    "$$\n",
    "GOOG.ExcessReturns = -0.0001211 + 1.1045703 * Mkt.RF - 0.6693132 * SMB - 0.3870928 * HML\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Structure\n",
    "\n",
    "A frequently used structure is a combination of loop and condition.\n",
    "First, let's try a `for` loop, which **iterates** over any vector type\n",
    "data.\n",
    "\n",
    "Let's loop over some vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Loop over a sequence, using the shorthand\n",
    "for (i in 1:6) {\n",
    "  print(i)\n",
    "}\n",
    "\n",
    "# Introduce the next loop\n",
    "print(\"next loop...\")\n",
    "\n",
    "# Mini-Exercise: Using a loop, print 1, 10, 100, 1000\n",
    "for (i in c(1, 10, 100, 1000)) {\n",
    "  print(i)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over a dataframe using its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Index loops over the first 10 rows of the Google closing price\n",
    "for (i in 1:10) {\n",
    "  print(trading_data$GOOG.Close[i])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4C: Loop and Conditions\n",
    "\n",
    "Loop over a sequence from 1 to 20 and print \"WOW\" for each odd number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 4C: loop and conditionals\n",
    "for (i in 1:20) {\n",
    "  if (i %% 2) {\n",
    "    print(\"WOW\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Introduce paste() and the need for print() inside loops\n",
    "\n",
    "for (i in 1:20) {\n",
    "  if (i %% 2) {\n",
    "    print(paste(i, \"WOW\"))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over *iterables* (i.e. objects that can be looped!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Our object Google close price is iterable so we can loop over those too!\n",
    "for (price in trading_data$GOOG.Close) {\n",
    "  print(price)\n",
    "  # That's a lot of rows... This is a good place for a conditional (and a break)!\n",
    "  if (price > 145) {\n",
    "    break\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render to PDF\n",
    "\n",
    "Now, *Render to PDF* again and check the output file.\n",
    "\n",
    "## The End\n",
    "\n",
    "That's all for this week.\n",
    "\n",
    "**But please read the supplement below!**\n",
    "\n",
    "# Supplement: Data cleaning\n",
    "\n",
    "In reality, the data will be **messy**. Some examples of **messy**\n",
    "are: - Additional unrelated data in our CSV files - Non-matching column\n",
    "names or types - Differences in data formats\n",
    "\n",
    "Data frames will rarely match up as nicely as you have seen above, so\n",
    "the following steps show how we achieve the above during the data\n",
    "cleaning stage.\n",
    "\n",
    "### Loading Messy Data\n",
    "\n",
    "Current FF3 data can be found at [the following\n",
    "link](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html).\n",
    "\n",
    "For this exercise, we'll use another trading data and FF3 data: -\n",
    "\"another_trading_wk4.csv\" - \"F-F_Research_Data_Factors_daily.CSV\"\n",
    "\n",
    "Loading the trading data is straightforward:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load trading data\n",
    "\n",
    "trading <- read.csv(\"another_trading_wk4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code below should load the CSV file. What happens instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Loading FF3\n",
    "\n",
    "ff3 <- read.csv(\"F-F_Research_Data_Factors_daily.CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the FF3 `.CSV` file in VS Code and see if you can find the issue.\n",
    "\n",
    "The `read.csv()` function accepts an additional argument called `skip`.\n",
    "**Add it to the code in the cell above to skip the first four rows.**\n",
    "\n",
    "Then use the code cell below to inspect the last rows of your FF3 data\n",
    "frame. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect FF3 data\n",
    "\n",
    "tail(ff3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some copyright information made its way into the table. Here\n",
    "are a few approaches to fix it - pick one and try it below to get some\n",
    "cleaner data.\n",
    "\n",
    "-   the `read.csv()` function has a numeric argument called `nrows` you\n",
    "    can use\n",
    "-   the `na.omit()` function returns a copy of your data frame with all\n",
    "    NA removed\n",
    "-   the `head()` function, with a negative `n` returns your data frame\n",
    "    with `-n` rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load FF3 data again\n",
    "\n",
    "ff3 <- read.csv(\"F-F_Research_Data_Factors_daily.CSV\", skip = 4)\n",
    "\n",
    "# alternative to the below, use nrows = 25543 in the line of code above\n",
    "\n",
    "ff3 <- na.omit(ff3)\n",
    "# alternatively, use:\n",
    "# ff3 <- head(ff3, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't Forget! Converting FF3 percentages to decimal\n",
    "\n",
    "Remember that our FF3 factor data comes in percentages, that we'll need\n",
    "in the decimal for our multiple regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Converting to decimal\n",
    "\n",
    "ff3[-1] <- ff3[-1] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Column Data\n",
    "\n",
    "As we saw, to merge different dataframes, we need column names, types\n",
    "and date formats to all match up.\n",
    "\n",
    "#### Renaming columns\n",
    "\n",
    "To rename columns, use `colnames()`, vector indexing and variable\n",
    "assignment. Let's rename the *ff3 data* date column to match the\n",
    "*trading data* date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Rename the first column in the FF3 data to Date\n",
    "\n",
    "colnames(ff3)[1] <- \"Date\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting date columns\n",
    "\n",
    "The importance of converting dates to the Date type is of the utmost\n",
    "here. Remember back to our work with the `as.Date()` function and\n",
    "convert date columns in both the FF3 and trading data to the Date type.\n",
    "This ensures the types and formats will match up for a merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Convert trading data\n",
    "\n",
    "trading$Date <- as.Date(trading$Date, format = \"%Y-%m-%d\")\n",
    "\n",
    "# Convert ff3 data\n",
    "ff3$Date <- as.Date(ff3$Date, format = \"%Y%m%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting our data\n",
    "\n",
    "To prepare for our FF3 multiple regression, we'll want to just select\n",
    "the Google subset of our trading data. To do so, we can use a condition\n",
    "in our indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# subsetting rows\n",
    "\n",
    "goog <- filter(trading, Ticker == \"GOOG\")\n",
    "head(goog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've just got Google data, we don't need the Ticker column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# subsetting columns\n",
    "\n",
    "goog <- goog[, c(2, 4)]\n",
    "head(goog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging dataframes\n",
    "\n",
    "Finally, we are ready to merge the trading data with the FF3 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Merging clean dataframes\n",
    "\n",
    "merged <- merge(goog, ff3, by = \"Date\")\n",
    "head(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we would normally proceed with calculating *daily returns* and\n",
    "*excess returns*, and then fitting our model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
